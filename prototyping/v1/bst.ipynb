{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c7d677-33b2-4d3c-852a-f43af84a03f7",
   "metadata": {},
   "source": [
    "**Tutorial**: https://keras.io/examples/structured_data/movielens_recommendations_transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6061f3f-dc76-4907-ba63-26f9fe35320d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "857bd5f4-a2d3-4517-a0c7-1b2195457415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import StringLookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01c0e9-641f-4519-8d53-48030d9560fe",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fc69c3-f85c-45b8-afc0-5dfe9928c780",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d9962cb-01f1-45d2-ab62-729718366579",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('Office_Products.csv', usecols=['rating', 'reviewerID', 'product_id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853b5094-bfac-4dda-be70-a46bb94c358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototyping 목적으로 50만 개의 행만 이용\n",
    "raw_df = raw_df.iloc[:500000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38366e0d-6a68-47fb-8554-987708d6156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.rename(columns={'reviewerID': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a1ac0d-180a-4842-b3e1-aa370422d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['rating'] = raw_df['rating'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8f6bf42-4590-46d8-9efb-20e1848be189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A2WJLOXXIB7NF3</td>\n",
       "      <td>0140503528</td>\n",
       "      <td>1162512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1RKICUK0GG6VF</td>\n",
       "      <td>0140503528</td>\n",
       "      <td>1147132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1QA5E50M398VW</td>\n",
       "      <td>0140503528</td>\n",
       "      <td>1142035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A3N0HBW8IP8CZQ</td>\n",
       "      <td>0140503528</td>\n",
       "      <td>980294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1K1JW1C5CUSUZ</td>\n",
       "      <td>0140503528</td>\n",
       "      <td>964915200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating         user_id  product_id        date\n",
       "0     3.0  A2WJLOXXIB7NF3  0140503528  1162512000\n",
       "1     5.0  A1RKICUK0GG6VF  0140503528  1147132800\n",
       "2     5.0  A1QA5E50M398VW  0140503528  1142035200\n",
       "3     5.0  A3N0HBW8IP8CZQ  0140503528   980294400\n",
       "4     5.0  A1K1JW1C5CUSUZ  0140503528   964915200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ce635-8e83-4a73-a52f-f0ee1f1ac1ce",
   "metadata": {},
   "source": [
    "### Transform data into sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77f1c9d-0917-4e42-b64c-39bc083d45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = raw_df.sort_values(by=['date']).groupby('user_id')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        'user_id': list(df_group.groups.keys()),\n",
    "        'product_id': list(df_group.product_id.apply(list)),\n",
    "        'rating': list(df_group.rating.apply(list)),\n",
    "        'date': list(df_group.date.apply(list)),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a0853e-4f88-4171-bbb3-927b96dc7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 3\n",
    "step_size = 1\n",
    "\n",
    "\n",
    "def create_sequences(values, window_size, step_size):\n",
    "    sequences = []\n",
    "    start_index = 0\n",
    "    while True:\n",
    "        end_index = start_index + window_size\n",
    "        seq = values[start_index:end_index]\n",
    "        if len(seq) < window_size:\n",
    "            seq = values[-window_size:]\n",
    "            if len(seq) == window_size:\n",
    "                sequences.append(seq)\n",
    "            break\n",
    "        sequences.append(seq)\n",
    "        start_index += step_size\n",
    "    return sequences\n",
    "\n",
    "\n",
    "df.product_id = df.product_id.apply(\n",
    "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
    ")\n",
    "\n",
    "df.rating = df.rating.apply(\n",
    "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
    ")\n",
    "\n",
    "del df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9c27e7-fc64-4caa-9414-819fde025c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 441528 entries, 0 to 441527\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   user_id     441528 non-null  object\n",
      " 1   product_id  46732 non-null   object\n",
      " 2   rating      46732 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# sequence_length 보다 product_id, rating 컬럼의 item 수가 적은 경우를 고려하지 않았기 때문에 값이 NaN으로 생성된 rows 존재\n",
    "df_transformed = df.explode(['product_id', 'rating'], ignore_index=True)\n",
    "df_transformed.info()\n",
    "\n",
    "# TODO: item 수에 flexible 한 embedding 방식 고민"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d7a9873-6099-4537-9feb-986164ac3c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id       False\n",
       "product_id    False\n",
       "rating        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.dropna(axis=0, how='any', inplace=True)\n",
    "df_transformed.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ee7cc3-451f-46df-991d-66fb4afd08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed.product_id = df_transformed.product_id.apply(lambda x: \",\".join(x))\n",
    "df_transformed.rating = df_transformed.rating.apply(lambda x: \",\".join([str(v) for v in x]))\n",
    "df_transformed.rename(columns={'product_id': 'seq_product_ids', 'rating': 'seq_ratings'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d197a8f-4b79-4e67-bea5-2bbf71d17d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>seq_product_ids</th>\n",
       "      <th>seq_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A0220159ZRNBTRKLG08H</td>\n",
       "      <td>8862930003,B00006IE7J,B00005249G</td>\n",
       "      <td>5.0,5.0,5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A0220159ZRNBTRKLG08H</td>\n",
       "      <td>B00006IE7J,B00005249G,B00006IEJC</td>\n",
       "      <td>5.0,5.0,5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A0220159ZRNBTRKLG08H</td>\n",
       "      <td>B00006IE7J,B00005249G,B00006IEJC</td>\n",
       "      <td>5.0,5.0,5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A03492194F0T997EZQ04</td>\n",
       "      <td>B00005249G,B00006JNNE,B00006IE7J</td>\n",
       "      <td>5.0,5.0,5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A03492194F0T997EZQ04</td>\n",
       "      <td>B00005249G,B00006JNNE,B00006IE7J</td>\n",
       "      <td>5.0,5.0,5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id                   seq_product_ids  seq_ratings\n",
       "16  A0220159ZRNBTRKLG08H  8862930003,B00006IE7J,B00005249G  5.0,5.0,5.0\n",
       "17  A0220159ZRNBTRKLG08H  B00006IE7J,B00005249G,B00006IEJC  5.0,5.0,5.0\n",
       "18  A0220159ZRNBTRKLG08H  B00006IE7J,B00005249G,B00006IEJC  5.0,5.0,5.0\n",
       "31  A03492194F0T997EZQ04  B00005249G,B00006JNNE,B00006IE7J  5.0,5.0,5.0\n",
       "32  A03492194F0T997EZQ04  B00005249G,B00006JNNE,B00006IE7J  5.0,5.0,5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7b47b4-cc5d-40f8-91d3-c4db8709225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_selection = np.random.rand(len(df_transformed.index)) <= 0.85\n",
    "train_data = df_transformed[random_selection]\n",
    "test_data = df_transformed[~random_selection]\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False, sep='|', header=False)\n",
    "test_data.to_csv('test_data.csv', index=False, sep='|', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57233e34-e856-46a3-8589-c196bd91414a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d94a2e-4a55-47c8-83c1-429243679f30",
   "metadata": {},
   "source": [
    "### Define metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc485961-5458-4c80-b741-0e3a7c5f7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = list(df_transformed.columns)\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    'user_id': list(df_transformed.user_id.unique()),\n",
    "    'product_id': list(df_transformed.seq_product_ids.unique()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af1ba0-cbad-47ab-963e-50c8f59841ba",
   "metadata": {},
   "source": [
    "### Create `tf.data.Dataset` for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e22bfbe5-8ae2-4880-91ae-4c8f0d0e971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
    "    def process(features):\n",
    "        product_ids_string = features['seq_product_ids']\n",
    "        seq_product_ids = tf.strings.split(product_ids_string, ',').to_tensor()\n",
    "\n",
    "        # The last product id in the sequence is the target product.\n",
    "        features['target_product_id'] = seq_product_ids[:, -1]\n",
    "        features['seq_product_ids'] = seq_product_ids[:, :-1]\n",
    "\n",
    "        ratings_string = features['seq_ratings']\n",
    "        seq_ratings = tf.strings.to_number(\n",
    "            tf.strings.split(ratings_string, \",\"), tf.dtypes.float32\n",
    "        ).to_tensor()\n",
    "\n",
    "        # The last rating in the sequence is the target for the model to predict.\n",
    "        target = seq_ratings[:, -1]\n",
    "        features['seq_ratings'] = seq_ratings[:, :-1]\n",
    "\n",
    "        return features, target\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        field_delim='|',\n",
    "        shuffle=shuffle,\n",
    "    ).map(process)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1e898-47f2-471f-a40b-99838436fff4",
   "metadata": {},
   "source": [
    "### Create model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a9cf4f2-fa37-4220-bfbb-680b16e92bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    return {\n",
    "        'user_id': layers.Input(name='user_id', shape=(1,), dtype=tf.string),\n",
    "        'seq_product_ids': layers.Input(\n",
    "            name='seq_product_ids', shape=(sequence_length - 1,), dtype=tf.string\n",
    "        ),\n",
    "        'target_product_id': layers.Input(\n",
    "            name='target_product_id', shape=(1,), dtype=tf.string\n",
    "        ),\n",
    "        'seq_ratings': layers.Input(\n",
    "            name='seq_ratings', shape=(sequence_length - 1,), dtype=tf.float32\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098d84c-b35a-433b-ad31-cb150d7adf4a",
   "metadata": {},
   "source": [
    "### Encode input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4e85894-871a-460c-9e4b-d7b0a8839696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input_features(\n",
    "    inputs,\n",
    "    include_user_id = True,\n",
    "    include_user_features = True,\n",
    "    include_product_features = True\n",
    "):\n",
    "\n",
    "    encoded_transformer_features = []\n",
    "    encoded_other_features = []\n",
    "\n",
    "    other_feature_names = []\n",
    "    if include_user_id:\n",
    "        other_feature_names.append('user_id')\n",
    "    if include_user_features:\n",
    "        other_feature_names.extend(USER_FEATURES)\n",
    "\n",
    "    ## Encode user features\n",
    "    for feature_name in other_feature_names:\n",
    "        # Convert the string input values into integer indices.\n",
    "        vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "        idx = StringLookup(vocabulary=vocabulary, mask_token=None, num_oov_indices=1)(\n",
    "            inputs[feature_name]\n",
    "        )\n",
    "        # Compute embedding dimensions\n",
    "        embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "        # Create an embedding layer with the specified dimensions.\n",
    "        embedding_encoder = layers.Embedding(\n",
    "            input_dim=len(vocabulary),\n",
    "            output_dim=embedding_dims,\n",
    "            name=f'{feature_name}_embedding',\n",
    "        )\n",
    "        # Convert the index values to embedding representations.\n",
    "        encoded_other_features.append(embedding_encoder(idx))\n",
    "\n",
    "    ## Create a single embedding vector for the user features\n",
    "    if len(encoded_other_features) > 1:\n",
    "        encoded_other_features = layers.concatenate(encoded_other_features)\n",
    "    elif len(encoded_other_features) == 1:\n",
    "        encoded_other_features = encoded_other_features[0]\n",
    "    else:\n",
    "        encoded_other_features = None\n",
    "\n",
    "    ## Create a product embedding encoder\n",
    "    product_vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[\"product_id\"]\n",
    "    product_embedding_dims = int(math.sqrt(len(product_vocabulary)))\n",
    "    # Create a lookup to convert string values to integer indices.\n",
    "    product_index_lookup = StringLookup(\n",
    "        vocabulary=product_vocabulary,\n",
    "        mask_token=None,\n",
    "        num_oov_indices=1,\n",
    "        name='product_index_lookup',\n",
    "    )\n",
    "    # Create an embedding layer with the specified dimensions.\n",
    "    product_embedding_encoder = layers.Embedding(\n",
    "        input_dim=len(product_vocabulary),\n",
    "        output_dim=product_embedding_dims,\n",
    "        name=f'product_embedding',\n",
    "    )\n",
    "\n",
    "    ## Define a function to encode a given product id.\n",
    "    def encode_product(product_id):\n",
    "        # Convert the string input values into integer indices.\n",
    "        product_idx = product_index_lookup(product_id)\n",
    "        product_embedding = product_embedding_encoder(product_idx)\n",
    "        encoded_product = product_embedding\n",
    "\n",
    "        return encoded_product\n",
    "\n",
    "    ## Encoding target_product_id\n",
    "    target_product_id = inputs['target_product_id']\n",
    "    encoded_target_product = encode_product(target_product_id)\n",
    "\n",
    "    ## Encoding sequence product_ids.\n",
    "    seq_product_ids = inputs['seq_product_ids']\n",
    "    encoded_seq_products = encode_product(seq_product_ids)\n",
    "    # Create positional embedding.\n",
    "    position_embedding_encoder = layers.Embedding(\n",
    "        input_dim=sequence_length,\n",
    "        output_dim=product_embedding_dims,\n",
    "        name='position_embedding',\n",
    "    )\n",
    "    positions = tf.range(start=0, limit=sequence_length - 1, delta=1)\n",
    "    encodded_positions = position_embedding_encoder(positions)\n",
    "    # Retrieve sequence ratings to incorporate them into the encoding of the product.\n",
    "    seq_ratings = tf.expand_dims(inputs['seq_ratings'], -1)\n",
    "    # Add the positional encoding to the product encodings and multiply them by rating.\n",
    "    encoded_seq_products_with_poistion_and_rating = layers.Multiply()(\n",
    "        [(encoded_seq_products + encodded_positions), seq_ratings]\n",
    "    )\n",
    "\n",
    "    # Construct the transformer inputs.\n",
    "    for encoded_product in tf.unstack(\n",
    "        encoded_seq_products_with_poistion_and_rating, axis=1\n",
    "    ):\n",
    "        encoded_transformer_features.append(tf.expand_dims(encoded_product, 1))\n",
    "    encoded_transformer_features.append(encoded_target_product)\n",
    "\n",
    "    encoded_transformer_features = layers.concatenate(\n",
    "        encoded_transformer_features, axis=1\n",
    "    )\n",
    "\n",
    "    return encoded_transformer_features, encoded_other_features\n",
    "\n",
    "\n",
    "# num_oov_indices 속성의 역할은?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11152d3-945c-41ca-9669-e407dea32a25",
   "metadata": {},
   "source": [
    "### Create a BST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52ef124a-1699-4ee7-9321-b457f23175be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 10:25:08.217705: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-28 10:25:10.392694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22311 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:5e:00.0, compute capability: 8.6\n",
      "2022-04-28 10:25:10.396019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:d9:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "include_user_id = False\n",
    "include_user_features = False\n",
    "include_product_features = False\n",
    "\n",
    "hidden_units = [256, 128]\n",
    "dropout_rate = 0.1\n",
    "num_heads = 3\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    inputs = create_model_inputs()\n",
    "    transformer_features, other_features = encode_input_features(\n",
    "        inputs, include_user_id, include_user_features\n",
    "    )\n",
    "\n",
    "    # Create a multi-headed attention layer.\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=transformer_features.shape[2], dropout=dropout_rate\n",
    "    )(transformer_features, transformer_features)\n",
    "\n",
    "    # Transformer block.\n",
    "    attention_output = layers.Dropout(dropout_rate)(attention_output)\n",
    "    x1 = layers.Add()([transformer_features, attention_output])\n",
    "    x1 = layers.LayerNormalization()(x1)\n",
    "    x2 = layers.LeakyReLU()(x1)\n",
    "    x2 = layers.Dense(units=x2.shape[-1])(x2)\n",
    "    x2 = layers.Dropout(dropout_rate)(x2)\n",
    "    transformer_features = layers.Add()([x1, x2])\n",
    "    transformer_features = layers.LayerNormalization()(transformer_features)\n",
    "    features = layers.Flatten()(transformer_features)\n",
    "\n",
    "    # Included the other features.\n",
    "    if other_features is not None:\n",
    "        features = layers.concatenate(\n",
    "            [features, layers.Reshape([other_features.shape[-1]])(other_features)]\n",
    "        )\n",
    "\n",
    "    # Fully-connected layers.\n",
    "    for num_units in hidden_units:\n",
    "        features = layers.Dense(num_units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.LeakyReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=1)(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a85e6-657b-4130-95c4-08e41c8bfa23",
   "metadata": {},
   "source": [
    "### Run training and evaluation experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4955993-9314-4cd7-a707-63fdf0c1f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 10:25:14.788164: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 4s 4s/step - loss: 24.3558 - mean_absolute_error: 4.7479"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 10:25:15.977529: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 10s 41ms/step - loss: 2.6278 - mean_absolute_error: 1.1986\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 6s 38ms/step - loss: 1.0598 - mean_absolute_error: 0.7509\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 6s 39ms/step - loss: 1.0080 - mean_absolute_error: 0.7215\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.9728 - mean_absolute_error: 0.7007\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 6s 40ms/step - loss: 0.9374 - mean_absolute_error: 0.6798\n",
      "Test MAE: 0.411\n"
     ]
    }
   ],
   "source": [
    "# Compile the model.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adagrad(learning_rate=0.01),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "\n",
    "# Read the training data.\n",
    "train_dataset = get_dataset_from_csv(\"train_data.csv\", shuffle=True, batch_size=265)\n",
    "\n",
    "# Fit the model with the training data.\n",
    "model.fit(train_dataset, epochs=5)\n",
    "\n",
    "# Read the test data.\n",
    "test_dataset = get_dataset_from_csv(\"test_data.csv\", batch_size=265)\n",
    "\n",
    "# Evaluate the model on the test data.\n",
    "_, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Test MAE: {round(rmse, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
